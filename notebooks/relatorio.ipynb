{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: João Otávio Palma\n",
    "\n",
    "Nome: Pedro Garcia Carneiro da Cunha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador automático sobre a Bolsa de valores brasileira (B3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As notícias tiveram o seu escopo dentro da parte de economia do IstoéDinheiro. Com isso, o foco o target foi a bolsa brasileira, avaliando as informações nacionais e internacionais que poderiam causar um aumento da bolsa ou uma queda da mesma. Dessa forma, houve uma separação entre assuntos irrelevantes(pouco impactantes ou com nenhum realcionamento com o target), neutros(indiferença na manipulação da bolsa de valores brasileira) e relevantes(possuem chance de gerar alguma alteração). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Bloco\" de funções que auxiliaram o classificador automático:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup --> retira caracteres especiais e os caracteres que encontram-se em Caps lock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "\n",
    "    #importando a string\n",
    "    punctuation = '[\\n!-:.?;,\")(~''/|\\*&%@#$_><}{ºª+=`]' \n",
    "    \n",
    "    pattern = re.compile(punctuation)\n",
    "    \n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text_subbed.lower()\n",
    "## Teste\n",
    "###textinho = 'hoje eu e o pedrão fomos ~ao shopping? talvez sim, talvez nao! \\n mas quem sabe - algumas pessoas foram: magali, cebolinha, magazine luiza (guilda)'\n",
    "\n",
    "###txtinho = cleanup(textinho)\n",
    "###print(txtinho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP (Natural Language Processing) --> uso de bibliotecas que tenham stopwords para melhorar o processamento do calssificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stpwd (l_p): # recebe uma lista de palavras para analisar\n",
    "    \n",
    "    l_p_filtradas = []\n",
    "    \n",
    "    p_stpwd = stopwords.words('portuguese') # Acessa a lista de \"stop words\" da língua portuguesa dentro da biblioteca NLTK\n",
    "    \n",
    "    for p in l_p: # p = palarvra\n",
    "        \n",
    "        if p not in p_stpwd: # verifica se a palavra não está presente na lista\n",
    "            \n",
    "            l_p_filtradas.append(p)\n",
    "    \n",
    "    return l_p_filtradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Laplace --> Realiza  a suavização dos valores para evitar falhas do contador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp (word, cat, port):\n",
    "    \n",
    "    α = 1\n",
    "    \n",
    "    if word in cat.index:\n",
    "        \n",
    "        freq_abs = cat.loc[word]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        freq_abs = 0\n",
    "        \n",
    "    tot = len(cat)\n",
    "    \n",
    "    rept = freq_abs\n",
    "    \n",
    "    outer_elements = len(port)\n",
    "    \n",
    "    # Aqui entra a fórmula de suavização de Laplace\n",
    "    \n",
    "    lp_suav = (rept + α) / (tot + outer_elements + α)\n",
    "    \n",
    "    return lp_suav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando onde o arquivo se encontra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório:\n",
      "C:\\Users\\pedro\\Documents\\GitHub\\22-2b-cd-p1-grupo_joaoogp\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório:')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando a base de dados com as notícias classificadas manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dados.xlsx', '~$dados.xlsx']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parece que o arquivo data/dados.xlsx está na pasta diretório correta\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/dados.xlsx'\n",
    "\n",
    "# Verificando se é possível achar o arquivo:\n",
    "\n",
    "if 'dados.xlsx' in os.listdir('data'):\n",
    "    print(f'Parece que o arquivo {filename} está na pasta diretório correta')\n",
    "    \n",
    "else:\n",
    "    print(f'Parece que o arquivo {filename} NÃO está na pasta diretório correta')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economia</td>\n",
       "      <td>Investimento Direto no País soma US$ 4,483 bi ...</td>\n",
       "      <td>Os Investimentos Diretos no País (IDP) somaram...</td>\n",
       "      <td>26/08/2022 10:23</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economia</td>\n",
       "      <td>‘Não queremos a chinesada entrando aqui quebra...</td>\n",
       "      <td>O ministro da Economia, Paulo Guedes, afirmou ...</td>\n",
       "      <td>26/08/2022 17:08</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economia</td>\n",
       "      <td>Presidente de petroleira russa morre ao cair d...</td>\n",
       "      <td>MOSCOU (Reuters) – Ravil Maganov, presidente d...</td>\n",
       "      <td>01/09/2022 16:51</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economia</td>\n",
       "      <td>PPI da Alemanha avança 37,2% em julho na compa...</td>\n",
       "      <td>O índice de preços ao produtor (PPI, na sigla ...</td>\n",
       "      <td>19/08/2022 07:19</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>Problema em traje de cosmonauta russo força fi...</td>\n",
       "      <td>Por Joey Roulette WASHINGTON (Reuters) – Um do...</td>\n",
       "      <td>17/08/2022 16:47</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categoria                                             Titulo  \\\n",
       "0  economia  Investimento Direto no País soma US$ 4,483 bi ...   \n",
       "1  economia  ‘Não queremos a chinesada entrando aqui quebra...   \n",
       "2  economia  Presidente de petroleira russa morre ao cair d...   \n",
       "3  economia  PPI da Alemanha avança 37,2% em julho na compa...   \n",
       "4  economia  Problema em traje de cosmonauta russo força fi...   \n",
       "\n",
       "                                           Descrição              Data  \\\n",
       "0  Os Investimentos Diretos no País (IDP) somaram...  26/08/2022 10:23   \n",
       "1  O ministro da Economia, Paulo Guedes, afirmou ...  26/08/2022 17:08   \n",
       "2  MOSCOU (Reuters) – Ravil Maganov, presidente d...  01/09/2022 16:51   \n",
       "3  O índice de preços ao produtor (PPI, na sigla ...  19/08/2022 07:19   \n",
       "4  Por Joey Roulette WASHINGTON (Reuters) – Um do...  17/08/2022 16:47   \n",
       "\n",
       "   Pagina  Target  \n",
       "0      47       2  \n",
       "1      46       0  \n",
       "2      22       1  \n",
       "3      72       1  \n",
       "4      78       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economia</td>\n",
       "      <td>Bolsonaro cita 1964 e ano do impeachment de Di...</td>\n",
       "      <td>Antes de sair do Palácio da Alvorada nesta qua...</td>\n",
       "      <td>07/09/2022 09:40</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economia</td>\n",
       "      <td>Investidores não veem guinada do Fed e se prep...</td>\n",
       "      <td>Por Gertrude Chavez-Dreyfuss NOVA YORK (Reuter...</td>\n",
       "      <td>24/08/2022 08:10</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economia</td>\n",
       "      <td>Ministro diz que enviou estudo do Porto de San...</td>\n",
       "      <td>O ministro da Infraestrutura, Marcelo Sampaio,...</td>\n",
       "      <td>01/09/2022 13:06</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economia</td>\n",
       "      <td>Missão da AIEA na usina de Zaporizhzhia “pode ...</td>\n",
       "      <td>KIEV (Reuters) – A missão de monitoramento da ...</td>\n",
       "      <td>01/09/2022 08:30</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>Bancos admitem ‘licença’ de R$ 70 bilhões</td>\n",
       "      <td>Representantes de bancos e fundos de investime...</td>\n",
       "      <td>16/08/2022 17:00</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categoria                                             Titulo  \\\n",
       "0  economia  Bolsonaro cita 1964 e ano do impeachment de Di...   \n",
       "1  economia  Investidores não veem guinada do Fed e se prep...   \n",
       "2  economia  Ministro diz que enviou estudo do Porto de San...   \n",
       "3  economia  Missão da AIEA na usina de Zaporizhzhia “pode ...   \n",
       "4  economia          Bancos admitem ‘licença’ de R$ 70 bilhões   \n",
       "\n",
       "                                           Descrição              Data  \\\n",
       "0  Antes de sair do Palácio da Alvorada nesta qua...  07/09/2022 09:40   \n",
       "1  Por Gertrude Chavez-Dreyfuss NOVA YORK (Reuter...  24/08/2022 08:10   \n",
       "2  O ministro da Infraestrutura, Marcelo Sampaio,...  01/09/2022 13:06   \n",
       "3  KIEV (Reuters) – A missão de monitoramento da ...  01/09/2022 08:30   \n",
       "4  Representantes de bancos e fundos de investime...  16/08/2022 17:00   \n",
       "\n",
       "   Pagina  Target  \n",
       "0       8       1  \n",
       "1      57       1  \n",
       "2      24       0  \n",
       "3      26       1  \n",
       "4      82       2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador automático\n",
    "\n",
    "No projeto 1, o ojetivo central do trabalho é criar um classificador de notícias baseado na descrição das mesmas. O material utilizado foi as notícias do site IstoÉ Dinheiro, onde as notícias envolvem tópicos relacionados à economia mundial. Com isso, a classificação foi feita do seguinte modo:\n",
    "\n",
    "0 - Notícias NEGATIVAS, ou seja, aquelas que interferem negativamente na bolsa de valores brasileira.\n",
    "1 - Notícias NEUTRAS, ou seja, aquelas que não impactam diretamente na bolsa de valores do Brasil.\n",
    "2 - Notícias POSITIVAS, ou seja, aquelas que interferem positivamente na bolsa de valores brasileira.\n",
    "\n",
    "Para realizar esse processo, o Teorema de Bayes foi utilizado para desenvolver um classificador Naive-Bayes. Ele consiste em examinar a ocorrência das palavras em uma dada categoria e determina a probabilidade de uma dada nova informação não classificada ser de uma categoria determinada a partir das palavras-chave da notícia.\n",
    "\n",
    "A base de dados de treinamento do algoritmo que foi utilizada foi uma série de notícicas classificadas manualmente. Isso serviu para o classificador determinar a frequência das palavras como dito anteriormente.\n",
    "\n",
    "O desenvolvimento do classificador consistiu em alguns cálculos de parâmetros que seriam utilizados no Teorema de Bayes:\n",
    "\n",
    "1.  $P(Notícia|Positiva)$: probabilidade de encontrar a notícia dentre as notícias Positivas;\n",
    "2.  $P(Notícia|Neutra)$: probabilidade de encontrar a notícia dentre as notícias Neutras;\n",
    "3.  $P(Notícia|Negativa)$: probabilidade de encontrar a notícia dentre as notícias Negativas;\n",
    "4.  $P(Positiva)$: probabilidade de ser Positiva;\n",
    "5.  $P(Neutra)$: probabilidade de ser Neutra;\n",
    "6.  $P(Negativa)$: probabilidade de ser Negativa;\n",
    "\n",
    "Com as variáveis já obtidas, tornou-se possível o cálculo das probabilidades de classificação das informações:\n",
    "\n",
    "* *Probabilidade de ser Positiva dado a notícia*:\n",
    "$$P(Positiva|Notícia) = \\frac{P(Notícia|Positiva) P(Positiva)}{P(Notícia)}$$\n",
    "\n",
    "* *Probabilidade de ser Negativa dado a notícia*:\n",
    "$$P(Negativa|Notícia) = \\frac{P(Notícia|Negativa) P(Negativa)}{P(Notícia)}$$\n",
    "\n",
    "* *Probabilidade de ser Neutra dado a notícia*:\n",
    "$$P(Neutra|Notícia) = \\frac{P(Notícia|Neutra) P(Neutra)}{P(Notícia)}$$\n",
    "\n",
    "Após obter as probabilidades, as notícias agora possuem condições de serem analisadas e classificadas pelo algoritmo.\n",
    "\n",
    "Além disso, a fim de melhoras o desempenho do classificador, o Suavizador de LaPlace foi utilizado, de modo a corrigir erros causados pelas palavras que não são encontradas na base de dados. E também, removendo as StopWords (palavras que não impactam na notícia, como pronomes e preposições)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de base de treinamento: Limpando o texto e separação da base com base no Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a base Train\n",
    "\n",
    "train.fillna(\"\",inplace=True)\n",
    "train['Descrição'] = train['Descrição'].apply(cleanup)\n",
    "train['Titulo'] = train['Titulo'].apply(cleanup)\n",
    "\n",
    "# Separando as variáveis de target em categorias\n",
    "\n",
    "train.Target = train.Target.astype('category')\n",
    "\n",
    "train.Target.cat.categories = (['Negativa' , 'Neutra', 'Positiva'])\n",
    "\n",
    "# Separando as noticias pela target\n",
    "\n",
    "not_positiva = train.loc[train['Target'] == 'Positiva']\n",
    "not_neutra = train.loc[train['Target'] == 'Neutra']\n",
    "not_negativa = train.loc[train['Target'] == 'Negativa']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificando de acordo com o descrição da notícia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista com os descrições de acordo com o target\n",
    "desc_positiva = list(not_positiva['Descrição'])\n",
    "desc_neutra = list(not_neutra['Descrição'])\n",
    "desc_negativa = list(not_negativa['Descrição'])\n",
    "\n",
    "\n",
    "# Notícias divididas em palavras e sem stopwords\n",
    "palavras_desc_positiva = stpwd(' '.join(desc_positiva).split())\n",
    "palavras_desc_neutra = stpwd(' '.join(desc_neutra).split())\n",
    "palavras_desc_negativa = stpwd(' '.join(desc_negativa).split())\n",
    "\n",
    "\n",
    "# Criando um conjunto que contém todas as palavras que estão presentes no título\n",
    "palavras_port_desc = palavras_desc_positiva + palavras_desc_neutra + palavras_desc_negativa\n",
    "palavras_port_desc = list(dict.fromkeys(palavras_port_desc))\n",
    "##print(palavras_port_desc)\n",
    "\n",
    "desc_positiva_series = pd.Series(palavras_desc_positiva)\n",
    "desc_neutra_series = pd.Series(palavras_desc_neutra)\n",
    "desc_negativa_series = pd.Series(palavras_desc_negativa)\n",
    "\n",
    "\n",
    "# Frequencia absoluta que as palavras aparecem nas notícias\n",
    "desc_positiva_abs = desc_positiva_series.value_counts()\n",
    "desc_neutras_abs = desc_neutra_series.value_counts()\n",
    "desc_negativa_abs = desc_negativa_series.value_counts()\n",
    "\n",
    "##print(desc_positiva_abs)\n",
    "\n",
    "##print(desc_neutras_abs)\n",
    "\n",
    "##print(desc_negativa_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificação_pela_Descrição</th>\n",
       "      <th>Negativa</th>\n",
       "      <th>Neutra</th>\n",
       "      <th>Positiva</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.161220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.302222</td>\n",
       "      <td>0.684444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificação_pela_Descrição  Negativa    Neutra  Positiva\n",
       "Target                                                    \n",
       "0                             0.017241  0.431034  0.551724\n",
       "1                             0.015251  0.823529  0.161220\n",
       "2                             0.013333  0.302222  0.684444"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidades: Positiva, Neutra ou Negativa\n",
    "prob_positiva = len(palavras_desc_positiva) /len(palavras_port_desc)\n",
    "prob_neutra = len(palavras_desc_neutra) /len(palavras_port_desc)\n",
    "prob_negativa = len(palavras_desc_negativa) /len(palavras_port_desc)\n",
    "\n",
    "# Probabilidade: Positiva, Neutra ou Negativa dada a Notícia\n",
    "lista_classifica_desc = []\n",
    "for not_desc in test.Descrição:\n",
    "\n",
    "    noticia_desc = cleanup(not_desc)\n",
    "    palavras_desc = stpwd(not_desc.split())\n",
    "\n",
    "    prob_Positiva_desc = 1\n",
    "    prob_Neutra_desc = 1\n",
    "    prob_Negativa_desc = 1\n",
    "\n",
    "    for p_desc in palavras_desc:\n",
    "        prob_Positiva_desc = prob_Positiva_desc * lp(p_desc, desc_positiva_abs,palavras_port_desc)\n",
    "\n",
    "        prob_Neutra_desc = prob_Neutra_desc * lp(p_desc,desc_neutras_abs, palavras_port_desc) \n",
    "\n",
    "        prob_Negativa_desc = prob_Negativa_desc * lp(p_desc,desc_negativa_abs,palavras_port_desc) \n",
    "\n",
    "    prob_Positiva_desc *= prob_positiva\n",
    "    prob_Neutra_desc *= prob_neutra\n",
    "    prob_Negativa_desc *= prob_negativa\n",
    "\n",
    "# Classificação da notícia com base nas probabilidades de ela ser Positiva, Neutra ou Negativa\n",
    "    if prob_Positiva_desc > prob_Neutra_desc and prob_Positiva_desc > prob_Negativa_desc:\n",
    "        lista_classifica_desc.append(\"Positiva\")\n",
    "    elif prob_Neutra_desc > prob_Positiva_desc and prob_Neutra_desc > prob_Negativa_desc:\n",
    "        lista_classifica_desc.append(\"Neutra\")\n",
    "    elif prob_Negativa_desc > prob_Positiva_desc and prob_Negativa_desc > prob_Neutra_desc:\n",
    "        lista_classifica_desc.append(\"Negativa\")\n",
    " \n",
    "target_desc = pd.Series(lista_classifica_desc)\n",
    "target_desc.value_counts(normalize=True)\n",
    "test[\"Classificação_pela_Descrição\"] = target_desc\n",
    "\n",
    "\n",
    "\n",
    "#test.Classificação_pela_Descrição = test.Classificação_pela_Descrição.astype('category')\n",
    "\n",
    "#test.Classificação_pela_Descrição.cat.categories = (['Negativa' , 'Neutra', 'Positiva'])\n",
    "\n",
    "\n",
    "# Comparação das classificações manuais e classificações feitas pelo algorítimo\n",
    "crosstab_desc_relativo = pd.crosstab(test[\"Target\"], test[\"Classificação_pela_Descrição\"], normalize=\"index\")\n",
    "crosstab_desc_relativo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Com os resultados obtidos podemos verificar como foi o acerto da classificação feita pelo contador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Porcentagem de *Positivos* (Verdadeiros e Falsos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.44444444444444\n",
      "71.29441815040192\n"
     ]
    }
   ],
   "source": [
    "# Verdadeiros\n",
    "\n",
    "positivos_verdadeiros_descrição = crosstab_desc_relativo.iloc[2, 2] * 100\n",
    "print(positivos_verdadeiros_descrição)\n",
    "\n",
    "# Falsos\n",
    "\n",
    "positivos_falsos_descrição = ((crosstab_desc_relativo.iloc[0, 2] + crosstab_desc_relativo.iloc[1, 2])) * 100\n",
    "print(positivos_falsos_descrição)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Porcentagem de *Negativos* (Verdadeiros e Falsos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7241379310344827\n",
      "2.85838779956427\n"
     ]
    }
   ],
   "source": [
    "# Verdadeiros\n",
    "\n",
    "negativos_verdadeiros_descrição = crosstab_desc_relativo.iloc[0, 0] * 100\n",
    "print(negativos_verdadeiros_descrição)\n",
    "\n",
    "# Falsos\n",
    "\n",
    "negativos_falsos_descrição = ((crosstab_desc_relativo.iloc[1, 0] + crosstab_desc_relativo.iloc[2, 0])) * 100\n",
    "print(negativos_falsos_descrição)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Porcentagem de *Neutros* (Verdadeiros e Falsos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.35294117647058\n",
      "73.32567049808429\n"
     ]
    }
   ],
   "source": [
    "# Verdadeiros\n",
    "\n",
    "neutros_verdadeiros_descrição = crosstab_desc_relativo.iloc[1, 1] * 100\n",
    "print(neutros_verdadeiros_descrição)\n",
    "\n",
    "# Falsos\n",
    "\n",
    "neutros_negativos_descrição = ((crosstab_desc_relativo.iloc[0, 1] + crosstab_desc_relativo.iloc[2, 1])) * 100\n",
    "print(neutros_negativos_descrição)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### *Acurácia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.75\n"
     ]
    }
   ],
   "source": [
    "test.Target = test.Target.astype('category')\n",
    "\n",
    "test.Target.cat.categories = (['Negativa' , 'Neutra', 'Positiva'])\n",
    "\n",
    "ac_descrição = (sum(test.Target == test['Classificação_pela_Descrição']) / len(test.Target)) * 100\n",
    "print(ac_descrição)\n",
    "\n",
    "ac1_desc = ((neutros_verdadeiros_descrição + negativos_verdadeiros_descrição + positivos_verdadeiros_descrição) / len(test.Target))*100\n",
    "#(ac1_desc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Análise dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador é competente em calcular a probabilidade de uma noticia ser neutra 82.35%, parcialmente preciso ao calcular a probailidade de uma notícia ser positiva 68.44% e impreciso ao tentar achar a mesma coisa para as notícias negativas 1.72%. Posto isso, ao realizarmos uma análise na base dados criada pode-se perceber uma quantidade maior de notícias classificadas como neutras quando comparadas a positivas e negativas, onde houveram mais positivas do que negativas.\n",
    "\n",
    "Ao analisarmos o cenário econômico global os mercados encontram-se em um processo de recuperação, mas já voltam a acontecer alguns crescimentos em diversos setores. Além disso, muitas notícias traziam informações dentro do aspecto político por estarmos em um ano de eleição e estas foram classificadas como neutras. Estes são alguns fatores que colaboraram para chegar nesse resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Mensagens com dupla negação e sarcasmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frases analisadas pelo classificador com dupla negação acabam aumentando a frequência da palavra, coisa que acaba aumentando a tendência da classificação para qual palavra apareceu mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Expansão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o futuro algo interessante seria aumentar a nossa acurácia e calibrar o contador de uma melhor forma. Isto é, aumentar a base de dados de notícias e tentar diminuir o viés da classificação manual realizada por integrantes distintos.\n",
    "\n",
    "Ademais, algo interessante de ser implementado seria usar lemmatization, recurso responsável por deixar as palavras encontradas em sua raíz lexical, isso diminui a probabilidade de falhas do contador por considerar \"sinônimos\" como sendo palavras distintas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Uso do classificador para aumentar o número de amostras com novas notícias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O contador usará a analise pré-estabelecida com a planilha anterior, assim esse aumento diminuiria a acurácia do mesmo, já que a classificação ficaria dependente da probabilidade existente, reforçando as variáveis com uma maior probabilidade me relação ao outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Novos usos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além do uso para controle de spam em emails mencionado em sala de aula este poderia ser usado para analisar sentimentos de pessoas ou pacientes, coisa que poderia vir a ser útil para o pré diagnóstico de algo sério que precisaria ser encamiado para uma profissional da área de saúde. Outro caso de uso plausível seria gerar um sistema de recomendação para pessoas interessadas em descobrir novos produtos que possuem um comportamento similiar ao que já estão habituadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas notícias. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas caterogias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por caterogia (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NLP com scikit-learn](https://dadosaocubo.com/nlp-com-scikit-learn/)\n",
    "\n",
    "[Text pre-processing: Stop words removal using differente libraries](https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a#:~:text=What%20are%20stop%20words%3F,much%20information%20to%20the%20text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
